{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('mode.chained_assignment',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'inputs'\n",
    "outputs = 'outputs'\n",
    "\n",
    "train = pd.read_csv(inputs + '/train.csv')\n",
    "target = pd.read_csv(inputs + '/test.csv')\n",
    "submission = pd.read_csv(outputs + '/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy().iloc[:, :-1]\n",
    "y_train = train.copy()['nerdiness']\n",
    "\n",
    "\n",
    "def onehot_encoder(dataframe, target, encoder=None):\n",
    "    if encoder == None:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        encoder.fit(dataframe[[target]])\n",
    "    ohe_df = encoder.transform(dataframe[[target]])\n",
    "    tag_function = lambda x: f'{target}_{x}'\n",
    "    ohe_df = pd.DataFrame(ohe_df, columns=list(map(tag_function, encoder.categories_[0])))\n",
    "    results = pd.concat([dataframe, ohe_df], axis=1)\n",
    "    \n",
    "    return results, encoder\n",
    "\n",
    "\n",
    "def preprocess(x, copy=True, encoders=None, scaler=None):\n",
    "    if copy:\n",
    "        x = x.copy()\n",
    "\n",
    "    # cast\n",
    "    int_list = [\n",
    "        'VCL1', 'VCL2', 'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8',\n",
    "        'VCL9', 'VCL10', 'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16',\n",
    "        'urban', 'age'\n",
    "    ]\n",
    "    for col in int_list:\n",
    "        x[col] = x[col].astype(float)\n",
    "\n",
    "    # isnull (missing values)\n",
    "    null_list = [\n",
    "        'Q1', 'Q2', 'Q3', 'Q4', 'Q5','Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13',\n",
    "        'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26',\n",
    "        'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10',\n",
    "        'education', 'gender', 'familysize']\n",
    "    for col in null_list:\n",
    "        x[f'{col}_isnull'] = np.where(pd.isnull(x[col]), 1.0, 0.0)\n",
    "\n",
    "    # mean (missing values)\n",
    "    mean_list = [\n",
    "        'Q1', 'Q2', 'Q3', 'Q4', 'Q5','Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13',\n",
    "        'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26',\n",
    "        'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10',\n",
    "        'familysize']\n",
    "    for col in mean_list:\n",
    "        x[col][pd.isnull(x[col])] = x[col].mean()\n",
    "\n",
    "    # value (missing values)\n",
    "    value_dict = {\n",
    "        'country': 'None',\n",
    "        'education': 1.5,\n",
    "        'gender': 0,\n",
    "        'engnat': 0,\n",
    "        'hand': 1,\n",
    "        'religion': 0,\n",
    "        'orientation': 0,\n",
    "        'voted': 0,\n",
    "        'married': 0,\n",
    "        'ASD': 0}\n",
    "    for col in value_dict:\n",
    "        x[col][pd.isnull(x[col])] = value_dict[col]\n",
    "\n",
    "    # value (0 values)\n",
    "    value0_dict = {\n",
    "        'urban': 1.5\n",
    "    }\n",
    "    for col in value0_dict:\n",
    "        x[f'{col}_isnull'] = np.where(x[col] == 0, 1.0, 0.0)\n",
    "        x[col][x[col] == 0] = value0_dict[col]\n",
    "\n",
    "    # OneHotEncoder\n",
    "    ohe_list = [\n",
    "        'country', 'gender', 'engnat', 'hand', 'religion',\n",
    "        'orientation', 'voted', 'married', 'ASD']\n",
    "    if encoders == None:\n",
    "        encoders = dict()\n",
    "    for col in ohe_list:\n",
    "        if col in encoders:\n",
    "            x, encoders[col] = onehot_encoder(x, col, encoder=encoders[col])\n",
    "        else:\n",
    "            x, encoders[col] = onehot_encoder(x, col)\n",
    "\n",
    "    # log (outlier)\n",
    "    log_list = [\n",
    "        'introelapse', 'testelapse', 'surveyelapse'\n",
    "    ]\n",
    "    for col in log_list:\n",
    "        x[f'log_{col}'] = np.log(x[col] + 1e-08)\n",
    "\n",
    "    # min-max cut (outlier)\n",
    "    outlier_dict = {\n",
    "        'age': {'min': 1, 'max': 100},\n",
    "        'log_introelapse': {'min': 0, 'max': 12},\n",
    "        'log_testelapse': {'min': 3, 'max': 8},\n",
    "        'log_surveyelapse': {'min': 0, 'max': 10},\n",
    "        'familysize': {'min': 1, 'max': 40}}\n",
    "    for col in outlier_dict:\n",
    "        x[col][x[col] > outlier_dict[col]['max']] = outlier_dict[col]['max']\n",
    "        x[col][x[col] < outlier_dict[col]['min']] = outlier_dict[col]['min']\n",
    "\n",
    "    # drop\n",
    "    drop_list = [\n",
    "        'index', \n",
    "        'country_AGO', 'country_ALA', 'country_ARM', 'country_AZE',\n",
    "        'country_BHS', 'country_BLR', 'country_BRB', 'country_BRN',\n",
    "        'country_BWA', 'country_DOM', 'country_ETH', 'country_FRO',\n",
    "        'country_GRL', 'country_GTM', 'country_GUF', 'country_GUY',\n",
    "        'country_IRQ', 'country_KAZ', 'country_KHM', 'country_LBY',\n",
    "        'country_LUX', 'country_MAC', 'country_MDV', 'country_MNP',\n",
    "        'country_MOZ', 'country_MUS', 'country_MWI', 'country_NAM',\n",
    "        'country_NPL', 'country_OMN', 'country_PAN', 'country_SDN',\n",
    "        'country_SSD', 'country_TUN', 'country_UGA', 'country_VGB',\n",
    "        'country_VIR', 'country_FSM', 'country_GEO', 'country_PNG',\n",
    "        'country_RWA', 'country_SYR', 'country_LAO', 'country_MNG',\n",
    "        'country_CUW', 'country_MLT', 'country_BHR', 'country_MDG'\n",
    "    ] + log_list + ohe_list\n",
    "    for col in drop_list:\n",
    "        x = x.drop(columns=col)\n",
    "\n",
    "    if scaler == None:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(x)\n",
    "    x = pd.DataFrame(scaler.transform(x), columns=x.columns, index=list(x.index.values))\n",
    "\n",
    "    return x, encoders, scaler\n",
    "\n",
    "X_train, encoders, scaler = preprocess(X_train, copy=False)\n",
    "X_target, _, _ = preprocess(target, encoders=encoders, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_weight_fraction_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.602699</td>\n",
       "      <td>1.167936</td>\n",
       "      <td>5.072100</td>\n",
       "      <td>1.942337</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.869630</td>\n",
       "      <td>0.866255</td>\n",
       "      <td>0.870623</td>\n",
       "      <td>0.885772</td>\n",
       "      <td>0.874008</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.487700</td>\n",
       "      <td>1.073181</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.877681</td>\n",
       "      <td>0.867912</td>\n",
       "      <td>0.865935</td>\n",
       "      <td>0.870162</td>\n",
       "      <td>0.885975</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.405600</td>\n",
       "      <td>0.388528</td>\n",
       "      <td>0.738299</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'cr...</td>\n",
       "      <td>0.877054</td>\n",
       "      <td>0.868837</td>\n",
       "      <td>0.866043</td>\n",
       "      <td>0.869887</td>\n",
       "      <td>0.885663</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2      31.602699      1.167936         5.072100        1.942337   \n",
       "0       8.487700      1.073181         0.326400        0.000200   \n",
       "1      15.405600      0.388528         0.738299        0.043400   \n",
       "\n",
       "  param_bootstrap param_class_weight param_criterion param_max_depth  \\\n",
       "2           False               None         entropy             200   \n",
       "0           False               None         entropy             200   \n",
       "1           False               None         entropy             200   \n",
       "\n",
       "  param_max_features param_min_samples_leaf param_min_samples_split  \\\n",
       "2               log2                      1                       3   \n",
       "0               log2                      1                       3   \n",
       "1               log2                      1                       3   \n",
       "\n",
       "  param_min_weight_fraction_leaf param_n_estimators param_n_jobs  \\\n",
       "2                            0.0               4096            4   \n",
       "0                            0.0               1024            4   \n",
       "1                            0.0               2048            4   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "2  {'bootstrap': False, 'class_weight': None, 'cr...           0.877757   \n",
       "0  {'bootstrap': False, 'class_weight': None, 'cr...           0.877681   \n",
       "1  {'bootstrap': False, 'class_weight': None, 'cr...           0.877054   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "2           0.869630           0.866255           0.870623           0.885772   \n",
       "0           0.867912           0.865935           0.870162           0.885975   \n",
       "1           0.868837           0.866043           0.869887           0.885663   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "2         0.874008        0.006974                1  \n",
       "0         0.873533        0.007385                2  \n",
       "1         0.873497        0.007085                3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\"\"\"\n",
    "n_estimators: int, default=100\n",
    "criterion: {'gini', 'entropy', 'log_loss'}, default='gini'\n",
    "max_depth: int, default=None\n",
    "min_samples_split: int or float, default=2\n",
    "min_samples_leaf: int or float, default=1\n",
    "min_weight_fraction_leaf: float, default=0.0\n",
    "max_features: {'sqrt', 'log2', None}, int or float, default='sqrt'\n",
    "max_leaf_nodes: int, default=None\n",
    "min_impurity_decrease: float, default=0.0\n",
    "bootstrap: bool, default=False\n",
    "oob_score: bool, default=False\n",
    "n_jobs: int, default=None\n",
    "class_weight: {'balanced', 'balanced_subsample'}, dict or list of dicts, default=None\n",
    "\"\"\"\n",
    "grid_parameters = {\n",
    "    'n_estimators': [1024, 2048, 4096],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [200],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "    'max_features': ['log2'],\n",
    "    'bootstrap': [False],\n",
    "    'n_jobs': [4],\n",
    "    'class_weight': [None],\n",
    "}\n",
    "\n",
    "grid_rfc = GridSearchCV(rfc, param_grid=grid_parameters, scoring='roc_auc', cv=5, refit=False)\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "pd.DataFrame(grid_rfc.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_weight_fraction_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.499795</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.455917</td>\n",
       "      <td>0.043411</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.872115</td>\n",
       "      <td>0.861581</td>\n",
       "      <td>0.857674</td>\n",
       "      <td>0.862496</td>\n",
       "      <td>0.883306</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.648301</td>\n",
       "      <td>1.153732</td>\n",
       "      <td>1.231941</td>\n",
       "      <td>0.085491</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.872435</td>\n",
       "      <td>0.860788</td>\n",
       "      <td>0.858016</td>\n",
       "      <td>0.862003</td>\n",
       "      <td>0.883221</td>\n",
       "      <td>0.867293</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.244721</td>\n",
       "      <td>13.988981</td>\n",
       "      <td>2.639110</td>\n",
       "      <td>1.016552</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.872189</td>\n",
       "      <td>0.860917</td>\n",
       "      <td>0.857696</td>\n",
       "      <td>0.862044</td>\n",
       "      <td>0.882377</td>\n",
       "      <td>0.867044</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.888373</td>\n",
       "      <td>0.525822</td>\n",
       "      <td>0.262488</td>\n",
       "      <td>0.054702</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.871262</td>\n",
       "      <td>0.861932</td>\n",
       "      <td>0.857103</td>\n",
       "      <td>0.861021</td>\n",
       "      <td>0.883056</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       8.499795      0.033387         0.455917        0.043411   \n",
       "2      21.648301      1.153732         1.231941        0.085491   \n",
       "3      53.244721     13.988981         2.639110        1.016552   \n",
       "0       4.888373      0.525822         0.262488        0.054702   \n",
       "\n",
       "  param_bootstrap  param_class_weight param_criterion param_max_depth  \\\n",
       "1           False  balanced_subsample         entropy             200   \n",
       "2           False  balanced_subsample         entropy             200   \n",
       "3           False  balanced_subsample         entropy             200   \n",
       "0           False  balanced_subsample         entropy             200   \n",
       "\n",
       "  param_max_features param_min_samples_leaf param_min_samples_split  \\\n",
       "1               sqrt                      1                       3   \n",
       "2               sqrt                      1                       3   \n",
       "3               sqrt                      1                       3   \n",
       "0               sqrt                      1                       3   \n",
       "\n",
       "  param_min_weight_fraction_leaf param_n_estimators param_n_jobs  \\\n",
       "1                            0.0               1024            4   \n",
       "2                            0.0               2048            4   \n",
       "3                            0.0               4096            4   \n",
       "0                            0.0                512            4   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'bootstrap': False, 'class_weight': 'balanced...           0.872115   \n",
       "2  {'bootstrap': False, 'class_weight': 'balanced...           0.872435   \n",
       "3  {'bootstrap': False, 'class_weight': 'balanced...           0.872189   \n",
       "0  {'bootstrap': False, 'class_weight': 'balanced...           0.871262   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.861581           0.857674           0.862496           0.883306   \n",
       "2           0.860788           0.858016           0.862003           0.883221   \n",
       "3           0.860917           0.857696           0.862044           0.882377   \n",
       "0           0.861932           0.857103           0.861021           0.883056   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.867434        0.009249                1  \n",
       "2         0.867293        0.009343                2  \n",
       "3         0.867044        0.009072                3  \n",
       "0         0.866875        0.009330                4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "\"\"\"\n",
    "n_estimators: int, default=100\n",
    "criterion: {'gini', 'entropy', 'log_loss'}, default='gini'\n",
    "max_depth: int, default=None\n",
    "min_samples_split: int or float, default=2\n",
    "min_samples_leaf: int or float, default=1\n",
    "min_weight_fraction_leaf: float, default=0.0\n",
    "max_features: {'sqrt', 'log2', None}, int or float, default='sqrt'\n",
    "max_leaf_nodes: int, default=None\n",
    "min_impurity_decrease: float, default=0.0\n",
    "bootstrap: bool, default=False\n",
    "oob_score: bool, default=False\n",
    "n_jobs: int, default=None\n",
    "class_weight: {'balanced', 'balanced_subsample'}, dict or list of dicts, default=None\n",
    "\"\"\"\n",
    "grid_parameters = {\n",
    "    'n_estimators': [512, 1024, 2048, 4096],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [200],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [False],\n",
    "    'n_jobs': [4],\n",
    "    'class_weight': ['balanced_subsample'],\n",
    "}\n",
    "\n",
    "grid_etc = GridSearchCV(rfc, param_grid=grid_parameters, scoring='roc_auc', cv=5, refit=False)\n",
    "grid_etc.fit(X_train, y_train)\n",
    "pd.DataFrame(grid_etc.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    gpu_id=0\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "n_estimators: [1,∞], default=1\n",
    "booster: {'gbtree', 'gblinear', 'dart'}, default='gbtree'\n",
    "learning_rate: [0,1], default=0.3\n",
    "min_split_loss: [0,∞], default=0\n",
    "max_depth: [0,∞], default=6\n",
    "min_child_weight: [0,∞], default=1\n",
    "max_delta_step: [0,∞], default=0\n",
    "subsample: (0,1], default=1\n",
    "sampling_method: {'uniform', 'gradient_based'}, default=uniform\n",
    "colsample_bytree: (0, 1], default=1\n",
    "colsample_bylevel: (0, 1], default=1\n",
    "colsample_bynode: (0, 1], default=1\n",
    "sketch_eps: (0, 1), default=0.03\n",
    "scale_pos_weight: default=1\n",
    "updater: {'grow_colmaker', 'grow_histmaker', 'grow_local_histmaker', 'grow_quantile_histmaker',\n",
    "          'grow_gpu_hist', 'sync', 'refresh', 'prune'}\n",
    "refresh_leaf: {0, 1}, default=1\n",
    "grow_policy: {'depthwise', 'lossguide'}, default='depthwise'\n",
    " - Only used if tree_method is set to hist, approx or gpu_hist.\n",
    "max_leaves: default=0\n",
    "max_bin: default=256\n",
    "num_parallel_tree: default=1\n",
    " - Only used if tree_method is set to hist, approx or gpu_hist.\n",
    "objective: {'reg:squarederror', 'reg:squaredlogerror', 'reg:logistic', 'reg:pseudohubererror',\n",
    "            'binary:logistic', 'binary:logitraw', 'binary:hinge'} default=reg:squarederror\n",
    " - Only used if tree_method is set to hist, approx or gpu_hist.\n",
    "\n",
    " * booster=dart\n",
    "sample_type: {'uniform', 'weighted'}, default='uniform'\n",
    "normalize_type: {'tree', 'forest'}, default='tree'\n",
    "rate_drop: [0.0, 1.0], default=0.0\n",
    "one_drop: {0, 1}, default=0\n",
    "skip_drop: [0.0, 1.0], default=0.0\n",
    "\n",
    " * booster=gblinear\n",
    "reg_lambda: default=1\n",
    "reg_alpha: default=0\n",
    "updater: {'shotgun', 'coord_descent'}, default='shotgun'\n",
    "feature_selector: {'cyclic', 'shuffle', 'random', 'greedy', 'thrifty'}, default='cyclic'\n",
    "top_k: default=0\n",
    " - Only used if feature_selector is 'greedy' or 'thrifty'\n",
    "\n",
    " * objective=reg:pseudohubererror\n",
    "huber_slope: default=1.0\n",
    "\"\"\"\n",
    "grid_parameters = {\n",
    "    'n_estimators': [16, 32],\n",
    "    'booster': ['gbtree'],\n",
    "    'learning_rate': [0.1],\n",
    "    'min_split_loss': [0],\n",
    "    'max_depth': [20, 21, 22],\n",
    "    'min_child_weight': [1],\n",
    "    'max_delta_step': [0],\n",
    "    'subsample': [0.7],\n",
    "    'sampling_method': ['uniform'],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'colsample_bylevel': [1],\n",
    "    'colsample_bynode': [1],\n",
    "    'sketch_eps': [0.03],\n",
    "    'scale_pos_weight': [1],\n",
    "    'refresh_leaf': [1],\n",
    "    'grow_policy': ['depthwise'],\n",
    "    'max_leaves': [0, 2048, 4096],\n",
    "    'max_bin': [256],\n",
    "    'num_parallel_tree': [16],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    # 'sample_type': ['uniform'],\n",
    "    # 'normalize_type': ['tree'],\n",
    "    # 'rate_drop': [0.05],\n",
    "    # 'one_drop': [0],\n",
    "    # 'skip_drop': [0.05],\n",
    "    # 'updater': ['grow_gpu_hist'],\n",
    "    # 'feature_selector': ['cyclic'],\n",
    "    # 'reg_lambda': [1],\n",
    "    # 'reg_alpha': [0],\n",
    "    # 'top_k': [0],\n",
    "    # 'huber_slope': [1.0]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(xgb, param_grid=grid_parameters, scoring='roc_auc', cv=5, refit=False)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "pd.DataFrame(grid_xgb.cv_results_).sort_values(by='rank_test_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0d89f1864a9bf14cab8f26b7808b33bb77607a1d02657216be50ded1f9f2bf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
